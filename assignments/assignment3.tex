% --------------------------------------------------------------
% This is all preamble stuff that you don't have to worry about.
% Head down to where it says "Start here"
% --------------------------------------------------------------

\documentclass[12pt]{article}

\usepackage[margin=1in]{geometry} 
\usepackage{amsmath,amsthm,amssymb}
\usepackage{color}

\makeatletter

\renewcommand\section{\@startsection {section}{1}{\z@}%
	{-3.5ex \@plus -1ex \@minus -.2ex}%
	{2.3ex \@plus.2ex}%
	{\normalfont\large\bfseries}}% from \Large
\renewcommand\subsection{\@startsection{subsection}{2}{\z@}%
	{-3.25ex\@plus -1ex \@minus -.2ex}%
	{1.5ex \@plus .2ex}%
	{\normalfont\large\bfseries}}% from \large
\makeatother

\begin{document}
	
	% --------------------------------------------------------------
	%                         Start here
	% --------------------------------------------------------------
	
	%\renewcommand{\qedsymbol}{\filledbox}
	
	\title{\textbf{Machine Learning Assignment \#3}\\
	Universit{\"a}t Bern}%replace X with the appropriate number
	\author{Lin Bai 09935404} %replace with your name
	
	\maketitle
	
	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
	%%%%%%   notations
	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%	\section*{notations}
%	$A, B, C\in \mathbb{R}^{n\times n}$ are $n\times n$ matrices, $x, a, b\in \mathbb{R}^n$ are column vectors.

	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
	%%%%%%   question 1
	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
	\section*{Solution of question 1}
	Since matrix $A$ is positive definite, $A$ is invertible and symmetric.\\
	According to the completion of squares, we have
	\begin{equation}{\label{comp_square}}
		\frac{1}{2}x^TAx+b^T+c = \frac{1}{2}(x+A^{-1}b)^TA(x+A^{-1}b)+c-\frac{1}{2}b^TA^{-1}b
	\end{equation}
	So
	\begin{equation}{\label{int_exp}}
	\begin{split}
	\begin{aligned}
		&\int_{x\in\mathbb{R}^n}exp\left(-\frac{1}{2}(x+A^{-1}b)^TA(x+A^{-1}b)-c+\frac{1}{2}b^TA^{-1}b\right)dx\\
		=&\int_{x\in\mathbb{R}^n}exp\left(-\frac{1}{2}(x+A^{-1}b)^TA(x+A^{-1}b)\right)exp(-c+\frac{1}{2}b^TA^{-1}b)dx\\
		=&exp(\frac{1}{2}b^TA^{-1}b-c)\int_{x\in\mathbb{R}^n}exp\left(-\frac{1}{2}(x+A^{-1}b)^TA(x+A^{-1}b)\right)dx
	\end{aligned}
	\end{split}
	\end{equation}
	According to the properties of Multivariate Gaussian,
	\begin{equation}{\label{gaus_int}}
		\int_{x\in\mathbb{R}^n}p(x;\mu,\varSigma)dx = 1
	\end{equation}
	\begin{equation}{\label{gaus_int_ext1}}
		\frac{1}{(2\pi)^{n/2}\mid\varSigma\mid^{1/2}}\int_{x\in\mathbb{R}^n}exp\left(-\frac{1}{2}(x-\mu)^T\varSigma^{-1}(x-\mu)\right)dx = 1
	\end{equation}
	\begin{equation}{\label{gaus_int_ext2}}
		\int_{x\in\mathbb{R}^n}exp\left(-\frac{1}{2}(x-\mu)^T\varSigma^{-1}(x-\mu)\right)dx = (2\pi)^{n/2}\mid\varSigma\mid^{1/2}
	\end{equation}
	\noindent
	Bring equation \ref{gaus_int_ext2} to equation \ref{int_exp}, we have
	\begin{equation}{\label{gaus_int_ext3}}
	\begin{aligned}
		&\int_{x\in\mathbb{R}^n}exp\left(-\frac{1}{2}(x+A^{-1}b)^TA(x+A^{-1}b)-c+\frac{1}{2}b^TA^{-1}b\right)dx\\
		=&exp(\frac{1}{2}b^TA^{-1}b-c)(2\pi)^{n/2}\mid\varSigma\mid^{1/2}
	\end{aligned}
	\end{equation}
	
	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
	%%%%%%   question 2
	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
	\section*{Solution of question 2}
	According to the mathematic definition of conditional probability function,
	\begin{equation}{\label{cond_proba_1}}
	\begin{split}
		f(x_1\mid x_2, \cdots x_n)=\frac{f(x1, x2, \cdots x_n)}{f(x2, \cdots x_n)}
	\end{split}
	\end{equation}
	\begin{equation}{\label{cond_proba_2}}
	\begin{aligned}
		f(x_1, x_2, \cdots x_n)&=f(x_n\mid x_1, \cdots x_{n-1})\cdot f(x1, x2, \cdots x_{n-1})\\
		&=f(x_n\mid x_1, \cdots x_{n-1})\cdot f(x_n\mid x_1, \cdots x_{n-2})\cdots f(x1, x2, \cdots x_{n-2})\\
		&=f(x_n\mid x_1, \cdots x_{n-1})\cdot f(x_n\mid x_1, \cdots x_{n-1})\cdots f(x_2\mid x_1)\cdot f(x_1)\\
		&=f(x_1)\prod_{i=2}^{n}f(x_i\mid x_1,\cdots,x_{i-1})
	\end{aligned}
	\end{equation}
	
	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
	%%%%%%   question 3, sub question (a)
	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
	\section*{Solution of question 3}
	\subsection*{(a)}
	Assume $cov[X, Y]\neq 0$, we get
	\begin{equation}{\label{covarience}}
	\begin{aligned}
		cov[X, Y]
		&=E[(X-E[X])(Y-E[Y]]\\
		&=E[XY-XE[X]-YE[Y]+E[X]E[Y]]\\
		&=E[XY]-E[X]E[Y]-E[Y]E[X]+E[X]E[Y]\\
		&=E[XY]-E[X]E[Y]\\
		&\neq 0
	\end{aligned}
	\end{equation}
	\noindent
	So we get $E[XY]\neq E[X]E[Y]$.
	However, since $X$ and $Y$ are independent, this means
	\begin{equation}{\label{independent}}
	\begin{aligned}
		E[XY]=E[X]E[Y]
	\end{aligned}
	\end{equation}
	Equation \ref{independent} and equation \ref{covarience} are contradict to each other. So the assumption is not true.\\
	Therefore, if $X$ and $Y$ are independent, $cov[X,Y]=0$.
	
	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
	%%%%%%   question 3, sub question (b)
	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
	\subsection*{(b)}
	\textbf{symmetric}\\
	According to the mathematic definition, $(i,j)$th element of the covariance matrix of n-dimension random variables $(X_1, X_2, ... , X_n$ is 
	\begin{equation}{\label{cov_ij}}
	\begin{aligned}
		C_{i,j}
		&=cov(X_i,X_j)\\
		&=E[(X_i-E[X_i])(X_j-E[X_j)]\\
		&=E[X_iX_j-X_iE[X_j]-X_jE[X_i]+E[X_i]E[X_j]\\
		&=E[X_iX_j]-E[X_i]E[X_j]-E[X_j]E[X_i]+E[X_i]E[X_j]\\
		&=E[X_iX_j]-E[X_i]E[X_j]
	\end{aligned}
	\end{equation}
	\noindent
	, where $i,j=1,2, ... ,n$.\\
	Since $E[X]E[Y]=E[Y]E[X]$,
	\begin{equation}{\label{cov_ji}}
	\begin{aligned}
		C_{j,i}=E[X_jX_i]-E[X_j]E[X_i]=E[X_iX_j]-E[X_i]E[X_j]
	\end{aligned}
	\end{equation}
	So $C_{i,j} = C_{j,i}$, this means covariance matrix is symmetric.\\
	\textbf{semi-definite}\\
	The covariance matrix is
	\begin{equation}{\label{cov_full}}
	\begin{aligned}
		\varSigma &= 
		\left(
		\begin{array}{ccc}
			cov[X_1,X_1], &\cdots, &cov[X_1X_n]\\
			cov[X_2,X_1], &\cdots, &cov[X_2X_n]\\
			\cdots\\
			cov[X_n,X_1], &\cdots, &cov[X_nX_n]\\
		\end{array}
		\right)\\
		&= 
		\left(
		\begin{array}{ccc}
			E[X_1X_1]-E[X_1]E[X_1], &\cdots, &E[X_1X_n]-E[X_1]E[X_n]\\
			E[X_1X_1]-E[X_1]E[X_1], &\cdots, &E[X_2X_n]-E[X_2]E[X_n]\\
			\cdots\\
			E[X_nX_n]-E[X_n]E[X_n], &\cdots, &E[X_nX_n]-E[X_n]E[X_n]\\
		\end{array}
		\right)\\
		&=E[XX^T]-E[X]E[X^T]\\
		&=E[(X-E[X])(X-E[X])^T]
	\end{aligned}
	\end{equation}
	
	\begin{equation}{\label{semi_defi}}
	\begin{aligned}
		z^T\varSigma z =z^TE[(X-E[X])(X-E[X])^T]z=E[z^T(X-E[X])(X-E[X])^Tz]
	\end{aligned}
	\end{equation}
	Assume $Y=z^T(X-E[X])$, equation \ref{semi_defi} is 
	\begin{equation}{\label{semi_defi_var1}}
	\begin{aligned}
		z^T\varSigma z =E[Y^TY]
	\end{aligned}
	\end{equation}
	Since $Y^TY\ge 0$, for any vector $z$,
	\begin{equation}{\label{semi_defi_var2}}
	\begin{aligned}
		z^T\varSigma z \ge 0
	\end{aligned}
	\end{equation}
	Therefore, covariance matrix is semi-definite.


	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
	%%%%%%   question 4
	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
	\section*{Solution of question 4}
	\begin{equation*}
	\begin{aligned}
		P(poor) &= P(Female, V0:40.5-, poor)+P(Female, V1:40.5+, poor)\\
		&+P(Male, V0:40.5-, poor)+P(Male, V1:40.5+, poor)\\
		&=0.253122+0.0421768+0.331313+0.134106\\
		&=0.7607178\\
		\\
		P(rich) &= P(Female, V0:40.5-, rich)+P(Female, V1:40.5+, rich)\\
		&+P(Male, V0:40.5-, rich)+P(Male, V1:40.5+, rich)\\
		&=0.0245895+0.0116293+0.0971295+0.105933\\
		&=0.2392813\\
		\\
		P(Male,poor) &= P(Male, V0:40.5-, poor)+P(Male, V1:40.5+, poor)\\
		&=0.331313+0.134106\\
		&=0.465419\\
		\\
		P(Male,rich) &= P(Male, V0:40.5-, rich)+P(Male, V1:40.5+, rich)\\
		&=0.0971295+0.105933\\
		&=0.2030625\\
		\\
		P(Male\mid poor) &= \frac{P(Male, poor)}{P(poor)}\\
		&=0.465419/0.7607178\\
		&=0.6118155\\
		\\
		P(Male\mid rich) &= \frac{P(Male, rich)}{P(rich)}\\
		&=0.2030625/0.2392813\\
		&=0.848635\\
		\\
		P(Female\mid poor) &= 1-P(Male\mid poor)\\
		&=1-0.6118155\\
		&=0.3881845\\
		\\
		P(Female\mid rich) &= 1-P(Male\mid rich)\\
		&=1-0.848635\\
		&=0.151365
	\end{aligned}
	\end{equation*}
	%%%%%%%%%%%%%%%%%%%%%%%%
	
	% --------------------------------------------------------------
	%     You don't have to mess with anything below this line.
	% --------------------------------------------------------------
	
\end{document}